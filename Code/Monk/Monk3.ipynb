{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.initializers import RandomUniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = loadtxt(\"/home/umair/Desktop/Data Science and BI/machine learning/Monk/monks-3.train\",\n",
    "                         delimiter=' ', usecols=range(1, 8))\n",
    "test3 = loadtxt(\"/home/umair/Desktop/Data Science and BI/machine learning/Monk/monks-3.test',\n",
    "                        delimiter=' ', usecols=range(1, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3=train3[:, 1:7]\n",
    "y_train3=train3[:, 0]\n",
    "\n",
    "X_test3=test3[:, 1:7]\n",
    "y_test3=test3[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc=OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3=enc.fit_transform(X_train3).toarray()\n",
    "\n",
    "X_test3=enc.fit_transform(X_test3).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_modelCV(lr=0.1, mom=0.1, act='sigmoid', alpha=0.001):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4, input_dim=17, kernel_initializer=RandomUniform(minval=-0.01, maxval=0.01, seed=1), \n",
    "                    activation=act, kernel_regularizer=l2(alpha)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', metrics=['accuracy'], optimizer= SGD(lr=lr, momentum=mom, nesterov=False))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      "122/122 [==============================] - 0s 736us/step - loss: 0.2496 - accuracy: 0.5410\n",
      "Epoch 2/150\n",
      "122/122 [==============================] - 0s 73us/step - loss: 0.2473 - accuracy: 0.6967\n",
      "Epoch 3/150\n",
      "122/122 [==============================] - 0s 58us/step - loss: 0.2432 - accuracy: 0.5492\n",
      "Epoch 4/150\n",
      "122/122 [==============================] - 0s 61us/step - loss: 0.2387 - accuracy: 0.6148\n",
      "Epoch 5/150\n",
      "122/122 [==============================] - 0s 97us/step - loss: 0.2341 - accuracy: 0.6066\n",
      "Epoch 6/150\n",
      "122/122 [==============================] - 0s 84us/step - loss: 0.2298 - accuracy: 0.7131\n",
      "Epoch 7/150\n",
      "122/122 [==============================] - 0s 106us/step - loss: 0.2256 - accuracy: 0.7131\n",
      "Epoch 8/150\n",
      "122/122 [==============================] - 0s 52us/step - loss: 0.2214 - accuracy: 0.7705\n",
      "Epoch 9/150\n",
      "122/122 [==============================] - 0s 85us/step - loss: 0.2172 - accuracy: 0.7049\n",
      "Epoch 10/150\n",
      "122/122 [==============================] - 0s 83us/step - loss: 0.2134 - accuracy: 0.8197\n",
      "Epoch 11/150\n",
      "122/122 [==============================] - 0s 103us/step - loss: 0.2093 - accuracy: 0.8607\n",
      "Epoch 12/150\n",
      "122/122 [==============================] - 0s 68us/step - loss: 0.2049 - accuracy: 0.8443\n",
      "Epoch 13/150\n",
      "122/122 [==============================] - 0s 85us/step - loss: 0.2013 - accuracy: 0.8525\n",
      "Epoch 14/150\n",
      "122/122 [==============================] - 0s 89us/step - loss: 0.1968 - accuracy: 0.8689\n",
      "Epoch 15/150\n",
      "122/122 [==============================] - 0s 101us/step - loss: 0.1933 - accuracy: 0.9016\n",
      "Epoch 16/150\n",
      "122/122 [==============================] - 0s 60us/step - loss: 0.1891 - accuracy: 0.8852\n",
      "Epoch 17/150\n",
      "122/122 [==============================] - 0s 105us/step - loss: 0.1859 - accuracy: 0.9098\n",
      "Epoch 18/150\n",
      "122/122 [==============================] - 0s 88us/step - loss: 0.1810 - accuracy: 0.9262\n",
      "Epoch 19/150\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.1771 - accuracy: 0.9262\n",
      "Epoch 20/150\n",
      "122/122 [==============================] - 0s 70us/step - loss: 0.1733 - accuracy: 0.9262\n",
      "Epoch 21/150\n",
      "122/122 [==============================] - 0s 99us/step - loss: 0.1694 - accuracy: 0.9262\n",
      "Epoch 22/150\n",
      "122/122 [==============================] - 0s 99us/step - loss: 0.1655 - accuracy: 0.9344\n",
      "Epoch 23/150\n",
      "122/122 [==============================] - 0s 77us/step - loss: 0.1618 - accuracy: 0.9344\n",
      "Epoch 24/150\n",
      "122/122 [==============================] - 0s 55us/step - loss: 0.1579 - accuracy: 0.9344\n",
      "Epoch 25/150\n",
      "122/122 [==============================] - 0s 119us/step - loss: 0.1542 - accuracy: 0.9344\n",
      "Epoch 26/150\n",
      "122/122 [==============================] - 0s 92us/step - loss: 0.1512 - accuracy: 0.9344\n",
      "Epoch 27/150\n",
      "122/122 [==============================] - 0s 79us/step - loss: 0.1474 - accuracy: 0.9344\n",
      "Epoch 28/150\n",
      "122/122 [==============================] - 0s 63us/step - loss: 0.1444 - accuracy: 0.9344\n",
      "Epoch 29/150\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.1409 - accuracy: 0.9344\n",
      "Epoch 30/150\n",
      "122/122 [==============================] - 0s 118us/step - loss: 0.1381 - accuracy: 0.9344\n",
      "Epoch 31/150\n",
      "122/122 [==============================] - 0s 77us/step - loss: 0.1352 - accuracy: 0.9344\n",
      "Epoch 32/150\n",
      "122/122 [==============================] - 0s 109us/step - loss: 0.1323 - accuracy: 0.9344\n",
      "Epoch 33/150\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.1293 - accuracy: 0.9344\n",
      "Epoch 34/150\n",
      "122/122 [==============================] - 0s 100us/step - loss: 0.1262 - accuracy: 0.9344\n",
      "Epoch 35/150\n",
      "122/122 [==============================] - 0s 124us/step - loss: 0.1237 - accuracy: 0.9344\n",
      "Epoch 36/150\n",
      "122/122 [==============================] - 0s 80us/step - loss: 0.1212 - accuracy: 0.9344\n",
      "Epoch 37/150\n",
      "122/122 [==============================] - 0s 121us/step - loss: 0.1188 - accuracy: 0.9344\n",
      "Epoch 38/150\n",
      "122/122 [==============================] - 0s 88us/step - loss: 0.1164 - accuracy: 0.9344\n",
      "Epoch 39/150\n",
      "122/122 [==============================] - 0s 69us/step - loss: 0.1141 - accuracy: 0.9344\n",
      "Epoch 40/150\n",
      "122/122 [==============================] - 0s 80us/step - loss: 0.1121 - accuracy: 0.9344\n",
      "Epoch 41/150\n",
      "122/122 [==============================] - 0s 83us/step - loss: 0.1099 - accuracy: 0.9344\n",
      "Epoch 42/150\n",
      "122/122 [==============================] - 0s 80us/step - loss: 0.1083 - accuracy: 0.9344\n",
      "Epoch 43/150\n",
      "122/122 [==============================] - 0s 105us/step - loss: 0.1062 - accuracy: 0.9344\n",
      "Epoch 44/150\n",
      "122/122 [==============================] - 0s 81us/step - loss: 0.1043 - accuracy: 0.9344\n",
      "Epoch 45/150\n",
      "122/122 [==============================] - 0s 64us/step - loss: 0.1028 - accuracy: 0.9344\n",
      "Epoch 46/150\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.1009 - accuracy: 0.9344\n",
      "Epoch 47/150\n",
      "122/122 [==============================] - 0s 111us/step - loss: 0.0996 - accuracy: 0.9344\n",
      "Epoch 48/150\n",
      "122/122 [==============================] - 0s 62us/step - loss: 0.0980 - accuracy: 0.9344\n",
      "Epoch 49/150\n",
      "122/122 [==============================] - 0s 102us/step - loss: 0.0968 - accuracy: 0.9344\n",
      "Epoch 50/150\n",
      "122/122 [==============================] - 0s 72us/step - loss: 0.0952 - accuracy: 0.9344\n",
      "Epoch 51/150\n",
      "122/122 [==============================] - 0s 88us/step - loss: 0.0941 - accuracy: 0.9344\n",
      "Epoch 52/150\n",
      "122/122 [==============================] - 0s 102us/step - loss: 0.0927 - accuracy: 0.9344\n",
      "Epoch 53/150\n",
      "122/122 [==============================] - 0s 76us/step - loss: 0.0915 - accuracy: 0.9344\n",
      "Epoch 54/150\n",
      "122/122 [==============================] - 0s 94us/step - loss: 0.0902 - accuracy: 0.9344\n",
      "Epoch 55/150\n",
      "122/122 [==============================] - 0s 116us/step - loss: 0.0893 - accuracy: 0.9344\n",
      "Epoch 56/150\n",
      "122/122 [==============================] - 0s 93us/step - loss: 0.0882 - accuracy: 0.9344\n",
      "Epoch 57/150\n",
      "122/122 [==============================] - 0s 86us/step - loss: 0.0872 - accuracy: 0.9344\n",
      "Epoch 58/150\n",
      "122/122 [==============================] - 0s 93us/step - loss: 0.0865 - accuracy: 0.9344\n",
      "Epoch 59/150\n",
      "122/122 [==============================] - 0s 54us/step - loss: 0.0853 - accuracy: 0.9344\n",
      "Epoch 60/150\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.0845 - accuracy: 0.9344\n",
      "Epoch 61/150\n",
      "122/122 [==============================] - 0s 94us/step - loss: 0.0837 - accuracy: 0.9344\n",
      "Epoch 62/150\n",
      "122/122 [==============================] - 0s 111us/step - loss: 0.0827 - accuracy: 0.9344\n",
      "Epoch 63/150\n",
      "122/122 [==============================] - 0s 56us/step - loss: 0.0820 - accuracy: 0.9344\n",
      "Epoch 64/150\n",
      "122/122 [==============================] - 0s 102us/step - loss: 0.0812 - accuracy: 0.9344\n",
      "Epoch 65/150\n",
      "122/122 [==============================] - 0s 75us/step - loss: 0.0805 - accuracy: 0.9344\n",
      "Epoch 66/150\n",
      "122/122 [==============================] - 0s 101us/step - loss: 0.0799 - accuracy: 0.9344\n",
      "Epoch 67/150\n",
      "122/122 [==============================] - 0s 51us/step - loss: 0.0793 - accuracy: 0.9344\n",
      "Epoch 68/150\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.0786 - accuracy: 0.9344\n",
      "Epoch 69/150\n",
      "122/122 [==============================] - 0s 95us/step - loss: 0.0779 - accuracy: 0.9344\n",
      "Epoch 70/150\n",
      "122/122 [==============================] - 0s 87us/step - loss: 0.0774 - accuracy: 0.9344\n",
      "Epoch 71/150\n",
      "122/122 [==============================] - 0s 50us/step - loss: 0.0766 - accuracy: 0.9344\n",
      "Epoch 72/150\n",
      "122/122 [==============================] - 0s 96us/step - loss: 0.0763 - accuracy: 0.9344\n",
      "Epoch 73/150\n",
      "122/122 [==============================] - 0s 78us/step - loss: 0.0755 - accuracy: 0.9344\n",
      "Epoch 74/150\n",
      "122/122 [==============================] - 0s 102us/step - loss: 0.0750 - accuracy: 0.9344\n",
      "Epoch 75/150\n",
      "122/122 [==============================] - 0s 50us/step - loss: 0.0746 - accuracy: 0.9344\n",
      "Epoch 76/150\n",
      "122/122 [==============================] - 0s 114us/step - loss: 0.0740 - accuracy: 0.9344\n",
      "Epoch 77/150\n",
      "122/122 [==============================] - 0s 97us/step - loss: 0.0734 - accuracy: 0.9344\n",
      "Epoch 78/150\n",
      "122/122 [==============================] - 0s 79us/step - loss: 0.0730 - accuracy: 0.9344\n",
      "Epoch 79/150\n",
      "122/122 [==============================] - 0s 70us/step - loss: 0.0725 - accuracy: 0.9344\n",
      "Epoch 80/150\n",
      "122/122 [==============================] - 0s 86us/step - loss: 0.0723 - accuracy: 0.9344\n",
      "Epoch 81/150\n",
      "122/122 [==============================] - 0s 78us/step - loss: 0.0719 - accuracy: 0.9344\n",
      "Epoch 82/150\n",
      "122/122 [==============================] - 0s 54us/step - loss: 0.0715 - accuracy: 0.9344\n",
      "Epoch 83/150\n",
      "122/122 [==============================] - 0s 71us/step - loss: 0.0709 - accuracy: 0.9344\n",
      "Epoch 84/150\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.0705 - accuracy: 0.9344\n",
      "Epoch 85/150\n",
      "122/122 [==============================] - 0s 86us/step - loss: 0.0703 - accuracy: 0.9344\n",
      "Epoch 86/150\n",
      "122/122 [==============================] - 0s 46us/step - loss: 0.0698 - accuracy: 0.9344\n",
      "Epoch 87/150\n",
      "122/122 [==============================] - 0s 54us/step - loss: 0.0693 - accuracy: 0.9344\n",
      "Epoch 88/150\n",
      "122/122 [==============================] - 0s 60us/step - loss: 0.0690 - accuracy: 0.9344\n",
      "Epoch 89/150\n",
      "122/122 [==============================] - 0s 103us/step - loss: 0.0687 - accuracy: 0.9344\n",
      "Epoch 90/150\n",
      "122/122 [==============================] - 0s 76us/step - loss: 0.0683 - accuracy: 0.9344\n",
      "Epoch 91/150\n",
      "122/122 [==============================] - 0s 53us/step - loss: 0.0679 - accuracy: 0.9344\n",
      "Epoch 92/150\n",
      "122/122 [==============================] - 0s 68us/step - loss: 0.0679 - accuracy: 0.9344\n",
      "Epoch 93/150\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.0677 - accuracy: 0.9344\n",
      "Epoch 94/150\n",
      "122/122 [==============================] - 0s 93us/step - loss: 0.0670 - accuracy: 0.9344\n",
      "Epoch 95/150\n",
      "122/122 [==============================] - 0s 56us/step - loss: 0.0668 - accuracy: 0.9344\n",
      "Epoch 96/150\n",
      "122/122 [==============================] - 0s 53us/step - loss: 0.0664 - accuracy: 0.9344\n",
      "Epoch 97/150\n",
      "122/122 [==============================] - 0s 79us/step - loss: 0.0663 - accuracy: 0.9344\n",
      "Epoch 98/150\n",
      "122/122 [==============================] - 0s 80us/step - loss: 0.0658 - accuracy: 0.9344\n",
      "Epoch 99/150\n",
      "122/122 [==============================] - 0s 60us/step - loss: 0.0658 - accuracy: 0.9344\n",
      "Epoch 100/150\n",
      "122/122 [==============================] - 0s 59us/step - loss: 0.0653 - accuracy: 0.9344\n",
      "Epoch 101/150\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.0649 - accuracy: 0.9344\n",
      "Epoch 102/150\n",
      "122/122 [==============================] - 0s 73us/step - loss: 0.0649 - accuracy: 0.9344\n",
      "Epoch 103/150\n",
      "122/122 [==============================] - 0s 67us/step - loss: 0.0647 - accuracy: 0.9344\n",
      "Epoch 104/150\n",
      "122/122 [==============================] - 0s 67us/step - loss: 0.0642 - accuracy: 0.9344\n",
      "Epoch 105/150\n",
      "122/122 [==============================] - 0s 57us/step - loss: 0.0640 - accuracy: 0.9344\n",
      "Epoch 106/150\n",
      "122/122 [==============================] - 0s 77us/step - loss: 0.0639 - accuracy: 0.9344\n",
      "Epoch 107/150\n",
      "122/122 [==============================] - 0s 84us/step - loss: 0.0635 - accuracy: 0.9344\n",
      "Epoch 108/150\n",
      "122/122 [==============================] - 0s 61us/step - loss: 0.0635 - accuracy: 0.9344\n",
      "Epoch 109/150\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.0630 - accuracy: 0.9344\n",
      "Epoch 110/150\n",
      "122/122 [==============================] - 0s 120us/step - loss: 0.0628 - accuracy: 0.9344\n",
      "Epoch 111/150\n",
      "122/122 [==============================] - 0s 89us/step - loss: 0.0627 - accuracy: 0.9344\n",
      "Epoch 112/150\n",
      "122/122 [==============================] - 0s 62us/step - loss: 0.0626 - accuracy: 0.9344\n",
      "Epoch 113/150\n",
      "122/122 [==============================] - 0s 57us/step - loss: 0.0624 - accuracy: 0.9344\n",
      "Epoch 114/150\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.0623 - accuracy: 0.9344\n",
      "Epoch 115/150\n",
      "122/122 [==============================] - 0s 81us/step - loss: 0.0617 - accuracy: 0.9344\n",
      "Epoch 116/150\n",
      "122/122 [==============================] - 0s 55us/step - loss: 0.0615 - accuracy: 0.9344\n",
      "Epoch 117/150\n",
      "122/122 [==============================] - 0s 54us/step - loss: 0.0613 - accuracy: 0.9344\n",
      "Epoch 118/150\n",
      "122/122 [==============================] - 0s 56us/step - loss: 0.0616 - accuracy: 0.9344\n",
      "Epoch 119/150\n",
      "122/122 [==============================] - 0s 126us/step - loss: 0.0609 - accuracy: 0.9344\n",
      "Epoch 120/150\n",
      "122/122 [==============================] - 0s 102us/step - loss: 0.0607 - accuracy: 0.9344\n",
      "Epoch 121/150\n",
      "122/122 [==============================] - 0s 54us/step - loss: 0.0605 - accuracy: 0.9344\n",
      "Epoch 122/150\n",
      "122/122 [==============================] - 0s 57us/step - loss: 0.0603 - accuracy: 0.9344\n",
      "Epoch 123/150\n",
      "122/122 [==============================] - 0s 105us/step - loss: 0.0603 - accuracy: 0.9344\n",
      "Epoch 124/150\n",
      "122/122 [==============================] - 0s 93us/step - loss: 0.0600 - accuracy: 0.9344\n",
      "Epoch 125/150\n",
      "122/122 [==============================] - 0s 63us/step - loss: 0.0599 - accuracy: 0.9344\n",
      "Epoch 126/150\n",
      "122/122 [==============================] - 0s 55us/step - loss: 0.0597 - accuracy: 0.9344\n",
      "Epoch 127/150\n",
      "122/122 [==============================] - 0s 101us/step - loss: 0.0594 - accuracy: 0.9344\n",
      "Epoch 128/150\n",
      "122/122 [==============================] - 0s 102us/step - loss: 0.0594 - accuracy: 0.9344\n",
      "Epoch 129/150\n",
      "122/122 [==============================] - 0s 55us/step - loss: 0.0593 - accuracy: 0.9344\n",
      "Epoch 130/150\n",
      "122/122 [==============================] - 0s 60us/step - loss: 0.0593 - accuracy: 0.9344\n",
      "Epoch 131/150\n",
      "122/122 [==============================] - 0s 95us/step - loss: 0.0589 - accuracy: 0.9344\n",
      "Epoch 132/150\n",
      "122/122 [==============================] - 0s 104us/step - loss: 0.0588 - accuracy: 0.9344\n",
      "Epoch 133/150\n",
      "122/122 [==============================] - 0s 64us/step - loss: 0.0585 - accuracy: 0.9344\n",
      "Epoch 134/150\n",
      "122/122 [==============================] - 0s 57us/step - loss: 0.0584 - accuracy: 0.9344\n",
      "Epoch 135/150\n",
      "122/122 [==============================] - 0s 68us/step - loss: 0.0584 - accuracy: 0.9344\n",
      "Epoch 136/150\n",
      "122/122 [==============================] - 0s 92us/step - loss: 0.0580 - accuracy: 0.9344\n",
      "Epoch 137/150\n",
      "122/122 [==============================] - 0s 89us/step - loss: 0.0579 - accuracy: 0.9344\n",
      "Epoch 138/150\n",
      "122/122 [==============================] - 0s 57us/step - loss: 0.0581 - accuracy: 0.9344\n",
      "Epoch 139/150\n",
      "122/122 [==============================] - 0s 62us/step - loss: 0.0578 - accuracy: 0.9344\n",
      "Epoch 140/150\n",
      "122/122 [==============================] - 0s 105us/step - loss: 0.0578 - accuracy: 0.9344\n",
      "Epoch 141/150\n",
      "122/122 [==============================] - 0s 113us/step - loss: 0.0575 - accuracy: 0.9344\n",
      "Epoch 142/150\n",
      "122/122 [==============================] - 0s 57us/step - loss: 0.0575 - accuracy: 0.9344\n",
      "Epoch 143/150\n",
      "122/122 [==============================] - 0s 60us/step - loss: 0.0570 - accuracy: 0.9344\n",
      "Epoch 144/150\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.0570 - accuracy: 0.9344\n",
      "Epoch 145/150\n",
      "122/122 [==============================] - 0s 106us/step - loss: 0.0570 - accuracy: 0.9344\n",
      "Epoch 146/150\n",
      "122/122 [==============================] - 0s 58us/step - loss: 0.0568 - accuracy: 0.9344\n",
      "Epoch 147/150\n",
      "122/122 [==============================] - 0s 56us/step - loss: 0.0568 - accuracy: 0.9344\n",
      "Epoch 148/150\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.0568 - accuracy: 0.9344\n",
      "Epoch 149/150\n",
      "122/122 [==============================] - 0s 126us/step - loss: 0.0563 - accuracy: 0.9344\n",
      "Epoch 150/150\n",
      "122/122 [==============================] - 0s 54us/step - loss: 0.0564 - accuracy: 0.9344\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "hyper_params_space = {\n",
    "        'lr': [0.1, 0.3, 0.5],\n",
    "        'mom': [0.01, 0.1, 0.2, 0.5, 0.8],\n",
    "        'act': ['relu'],\n",
    "        'alpha': [1e-5, 1e-10, 1e-15, 1e-20]\n",
    "    },\n",
    "\n",
    "\n",
    "\n",
    "print('===================================')\n",
    "model = KerasClassifier(build_fn=create_modelCV, batch_size=25, epochs=150)\n",
    "mlpr = GridSearchCV( model\n",
    "                    , hyper_params_space, scoring=['accuracy'], refit='accuracy', cv=3, n_jobs=2)\n",
    "mlpr.fit(X_train3, y_train3)\n",
    "print(\"DONE\")\n",
    "resultGSCV=pd.DataFrame(mlpr.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'act': 'relu', 'alpha': 1e-05, 'lr': 0.1, 'mom': 0.1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_modelOP():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4, input_dim=17, activation=mlpr.best_params_['act'], \n",
    "                    kernel_initializer=RandomUniform(minval=-0.01, maxval=0.01, seed=1),\n",
    "                   kernel_regularizer=l2(mlpr.best_params_['alpha'])))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', metrics=['accuracy'], \n",
    "                  optimizer= SGD(lr=mlpr.best_params_['lr'], \n",
    "                                 momentum=mlpr.best_params_['mom']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 122 samples, validate on 432 samples\n",
      "Epoch 1/150\n",
      "122/122 [==============================] - 0s 958us/step - loss: 0.2489 - accuracy: 0.6066 - val_loss: 0.2461 - val_accuracy: 0.9282\n",
      "Epoch 2/150\n",
      "122/122 [==============================] - 0s 205us/step - loss: 0.2445 - accuracy: 0.8934 - val_loss: 0.2413 - val_accuracy: 0.9491\n",
      "Epoch 3/150\n",
      "122/122 [==============================] - 0s 149us/step - loss: 0.2399 - accuracy: 0.8934 - val_loss: 0.2363 - val_accuracy: 0.9213\n",
      "Epoch 4/150\n",
      "122/122 [==============================] - 0s 195us/step - loss: 0.2352 - accuracy: 0.9016 - val_loss: 0.2313 - val_accuracy: 0.9167\n",
      "Epoch 5/150\n",
      "122/122 [==============================] - 0s 143us/step - loss: 0.2305 - accuracy: 0.9180 - val_loss: 0.2259 - val_accuracy: 0.9074\n",
      "Epoch 6/150\n",
      "122/122 [==============================] - 0s 170us/step - loss: 0.2253 - accuracy: 0.8770 - val_loss: 0.2205 - val_accuracy: 0.9259\n",
      "Epoch 7/150\n",
      "122/122 [==============================] - 0s 180us/step - loss: 0.2197 - accuracy: 0.9098 - val_loss: 0.2151 - val_accuracy: 0.9375\n",
      "Epoch 8/150\n",
      "122/122 [==============================] - 0s 229us/step - loss: 0.2141 - accuracy: 0.9180 - val_loss: 0.2097 - val_accuracy: 0.9491\n",
      "Epoch 9/150\n",
      "122/122 [==============================] - 0s 146us/step - loss: 0.2088 - accuracy: 0.9180 - val_loss: 0.2042 - val_accuracy: 0.9491\n",
      "Epoch 10/150\n",
      "122/122 [==============================] - 0s 185us/step - loss: 0.2033 - accuracy: 0.9262 - val_loss: 0.1987 - val_accuracy: 0.9583\n",
      "Epoch 11/150\n",
      "122/122 [==============================] - 0s 142us/step - loss: 0.1980 - accuracy: 0.9262 - val_loss: 0.1931 - val_accuracy: 0.9606\n",
      "Epoch 12/150\n",
      "122/122 [==============================] - 0s 164us/step - loss: 0.1926 - accuracy: 0.9262 - val_loss: 0.1873 - val_accuracy: 0.9630\n",
      "Epoch 13/150\n",
      "122/122 [==============================] - 0s 175us/step - loss: 0.1867 - accuracy: 0.9262 - val_loss: 0.1815 - val_accuracy: 0.9630\n",
      "Epoch 14/150\n",
      "122/122 [==============================] - 0s 148us/step - loss: 0.1812 - accuracy: 0.9262 - val_loss: 0.1757 - val_accuracy: 0.9630\n",
      "Epoch 15/150\n",
      "122/122 [==============================] - 0s 213us/step - loss: 0.1768 - accuracy: 0.9262 - val_loss: 0.1694 - val_accuracy: 0.9630\n",
      "Epoch 16/150\n",
      "122/122 [==============================] - 0s 139us/step - loss: 0.1698 - accuracy: 0.9262 - val_loss: 0.1637 - val_accuracy: 0.9722\n",
      "Epoch 17/150\n",
      "122/122 [==============================] - 0s 203us/step - loss: 0.1646 - accuracy: 0.9344 - val_loss: 0.1579 - val_accuracy: 0.9722\n",
      "Epoch 18/150\n",
      "122/122 [==============================] - 0s 149us/step - loss: 0.1587 - accuracy: 0.9344 - val_loss: 0.1522 - val_accuracy: 0.9722\n",
      "Epoch 19/150\n",
      "122/122 [==============================] - 0s 174us/step - loss: 0.1533 - accuracy: 0.9344 - val_loss: 0.1464 - val_accuracy: 0.9722\n",
      "Epoch 20/150\n",
      "122/122 [==============================] - 0s 147us/step - loss: 0.1482 - accuracy: 0.9344 - val_loss: 0.1406 - val_accuracy: 0.9722\n",
      "Epoch 21/150\n",
      "122/122 [==============================] - 0s 166us/step - loss: 0.1432 - accuracy: 0.9344 - val_loss: 0.1356 - val_accuracy: 0.9722\n",
      "Epoch 22/150\n",
      "122/122 [==============================] - 0s 187us/step - loss: 0.1382 - accuracy: 0.9344 - val_loss: 0.1305 - val_accuracy: 0.9722\n",
      "Epoch 23/150\n",
      "122/122 [==============================] - 0s 150us/step - loss: 0.1336 - accuracy: 0.9344 - val_loss: 0.1254 - val_accuracy: 0.9722\n",
      "Epoch 24/150\n",
      "122/122 [==============================] - 0s 213us/step - loss: 0.1294 - accuracy: 0.9344 - val_loss: 0.1210 - val_accuracy: 0.9722\n",
      "Epoch 25/150\n",
      "122/122 [==============================] - 0s 140us/step - loss: 0.1251 - accuracy: 0.9344 - val_loss: 0.1163 - val_accuracy: 0.9722\n",
      "Epoch 26/150\n",
      "122/122 [==============================] - 0s 198us/step - loss: 0.1206 - accuracy: 0.9344 - val_loss: 0.1118 - val_accuracy: 0.9722\n",
      "Epoch 27/150\n",
      "122/122 [==============================] - 0s 148us/step - loss: 0.1174 - accuracy: 0.9344 - val_loss: 0.1075 - val_accuracy: 0.9722\n",
      "Epoch 28/150\n",
      "122/122 [==============================] - 0s 207us/step - loss: 0.1133 - accuracy: 0.9344 - val_loss: 0.1034 - val_accuracy: 0.9722\n",
      "Epoch 29/150\n",
      "122/122 [==============================] - 0s 146us/step - loss: 0.1098 - accuracy: 0.9344 - val_loss: 0.0994 - val_accuracy: 0.9722\n",
      "Epoch 30/150\n",
      "122/122 [==============================] - 0s 195us/step - loss: 0.1072 - accuracy: 0.9344 - val_loss: 0.0961 - val_accuracy: 0.9722\n",
      "Epoch 31/150\n",
      "122/122 [==============================] - 0s 141us/step - loss: 0.1034 - accuracy: 0.9344 - val_loss: 0.0927 - val_accuracy: 0.9722\n",
      "Epoch 32/150\n",
      "122/122 [==============================] - 0s 146us/step - loss: 0.1004 - accuracy: 0.9344 - val_loss: 0.0894 - val_accuracy: 0.9722\n",
      "Epoch 33/150\n",
      "122/122 [==============================] - 0s 182us/step - loss: 0.0978 - accuracy: 0.9344 - val_loss: 0.0866 - val_accuracy: 0.9722\n",
      "Epoch 34/150\n",
      "122/122 [==============================] - 0s 148us/step - loss: 0.0953 - accuracy: 0.9344 - val_loss: 0.0833 - val_accuracy: 0.9722\n",
      "Epoch 35/150\n",
      "122/122 [==============================] - 0s 211us/step - loss: 0.0930 - accuracy: 0.9344 - val_loss: 0.0808 - val_accuracy: 0.9722\n",
      "Epoch 36/150\n",
      "122/122 [==============================] - 0s 149us/step - loss: 0.0906 - accuracy: 0.9344 - val_loss: 0.0782 - val_accuracy: 0.9722\n",
      "Epoch 37/150\n",
      "122/122 [==============================] - 0s 199us/step - loss: 0.0889 - accuracy: 0.9344 - val_loss: 0.0760 - val_accuracy: 0.9722\n",
      "Epoch 38/150\n",
      "122/122 [==============================] - 0s 143us/step - loss: 0.0867 - accuracy: 0.9344 - val_loss: 0.0737 - val_accuracy: 0.9722\n",
      "Epoch 39/150\n",
      "122/122 [==============================] - 0s 183us/step - loss: 0.0850 - accuracy: 0.9344 - val_loss: 0.0716 - val_accuracy: 0.9722\n",
      "Epoch 40/150\n",
      "122/122 [==============================] - 0s 150us/step - loss: 0.0833 - accuracy: 0.9344 - val_loss: 0.0696 - val_accuracy: 0.9722\n",
      "Epoch 41/150\n",
      "122/122 [==============================] - 0s 158us/step - loss: 0.0817 - accuracy: 0.9344 - val_loss: 0.0681 - val_accuracy: 0.9722\n",
      "Epoch 42/150\n",
      "122/122 [==============================] - 0s 191us/step - loss: 0.0801 - accuracy: 0.9344 - val_loss: 0.0662 - val_accuracy: 0.9722\n",
      "Epoch 43/150\n",
      "122/122 [==============================] - 0s 152us/step - loss: 0.0789 - accuracy: 0.9344 - val_loss: 0.0647 - val_accuracy: 0.9722\n",
      "Epoch 44/150\n",
      "122/122 [==============================] - 0s 230us/step - loss: 0.0779 - accuracy: 0.9344 - val_loss: 0.0629 - val_accuracy: 0.9722\n",
      "Epoch 45/150\n",
      "122/122 [==============================] - 0s 145us/step - loss: 0.0766 - accuracy: 0.9344 - val_loss: 0.0614 - val_accuracy: 0.9722\n",
      "Epoch 46/150\n",
      "122/122 [==============================] - 0s 201us/step - loss: 0.0755 - accuracy: 0.9344 - val_loss: 0.0601 - val_accuracy: 0.9722\n",
      "Epoch 47/150\n",
      "122/122 [==============================] - 0s 140us/step - loss: 0.0742 - accuracy: 0.9344 - val_loss: 0.0592 - val_accuracy: 0.9722\n",
      "Epoch 48/150\n",
      "122/122 [==============================] - 0s 201us/step - loss: 0.0735 - accuracy: 0.9344 - val_loss: 0.0580 - val_accuracy: 0.9722\n",
      "Epoch 49/150\n",
      "122/122 [==============================] - 0s 144us/step - loss: 0.0724 - accuracy: 0.9344 - val_loss: 0.0568 - val_accuracy: 0.9722\n",
      "Epoch 50/150\n",
      "122/122 [==============================] - 0s 147us/step - loss: 0.0717 - accuracy: 0.9344 - val_loss: 0.0558 - val_accuracy: 0.9722\n",
      "Epoch 51/150\n",
      "122/122 [==============================] - 0s 187us/step - loss: 0.0707 - accuracy: 0.9344 - val_loss: 0.0548 - val_accuracy: 0.9722\n",
      "Epoch 52/150\n",
      "122/122 [==============================] - 0s 165us/step - loss: 0.0700 - accuracy: 0.9344 - val_loss: 0.0540 - val_accuracy: 0.9722\n",
      "Epoch 53/150\n",
      "122/122 [==============================] - 0s 187us/step - loss: 0.0693 - accuracy: 0.9344 - val_loss: 0.0533 - val_accuracy: 0.9722\n",
      "Epoch 54/150\n",
      "122/122 [==============================] - 0s 155us/step - loss: 0.0689 - accuracy: 0.9344 - val_loss: 0.0526 - val_accuracy: 0.9722\n",
      "Epoch 55/150\n",
      "122/122 [==============================] - 0s 214us/step - loss: 0.0682 - accuracy: 0.9344 - val_loss: 0.0517 - val_accuracy: 0.9722\n",
      "Epoch 56/150\n",
      "122/122 [==============================] - 0s 149us/step - loss: 0.0673 - accuracy: 0.9344 - val_loss: 0.0510 - val_accuracy: 0.9722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "122/122 [==============================] - 0s 188us/step - loss: 0.0670 - accuracy: 0.9344 - val_loss: 0.0504 - val_accuracy: 0.9722\n",
      "Epoch 58/150\n",
      "122/122 [==============================] - 0s 140us/step - loss: 0.0665 - accuracy: 0.9344 - val_loss: 0.0502 - val_accuracy: 0.9722\n",
      "Epoch 59/150\n",
      "122/122 [==============================] - 0s 181us/step - loss: 0.0658 - accuracy: 0.9344 - val_loss: 0.0497 - val_accuracy: 0.9722\n",
      "Epoch 60/150\n",
      "122/122 [==============================] - 0s 149us/step - loss: 0.0652 - accuracy: 0.9344 - val_loss: 0.0490 - val_accuracy: 0.9722\n",
      "Epoch 61/150\n",
      "122/122 [==============================] - 0s 180us/step - loss: 0.0648 - accuracy: 0.9344 - val_loss: 0.0483 - val_accuracy: 0.9722\n",
      "Epoch 62/150\n",
      "122/122 [==============================] - 0s 145us/step - loss: 0.0643 - accuracy: 0.9344 - val_loss: 0.0479 - val_accuracy: 0.9722\n",
      "Epoch 63/150\n",
      "122/122 [==============================] - 0s 160us/step - loss: 0.0640 - accuracy: 0.9344 - val_loss: 0.0473 - val_accuracy: 0.9722\n",
      "Epoch 64/150\n",
      "122/122 [==============================] - 0s 166us/step - loss: 0.0636 - accuracy: 0.9344 - val_loss: 0.0471 - val_accuracy: 0.9722\n",
      "Epoch 65/150\n",
      "122/122 [==============================] - 0s 153us/step - loss: 0.0632 - accuracy: 0.9344 - val_loss: 0.0468 - val_accuracy: 0.9722\n",
      "Epoch 66/150\n",
      "122/122 [==============================] - 0s 210us/step - loss: 0.0629 - accuracy: 0.9344 - val_loss: 0.0464 - val_accuracy: 0.9722\n",
      "Epoch 67/150\n",
      "122/122 [==============================] - 0s 142us/step - loss: 0.0625 - accuracy: 0.9344 - val_loss: 0.0459 - val_accuracy: 0.9722\n",
      "Epoch 68/150\n",
      "122/122 [==============================] - 0s 201us/step - loss: 0.0624 - accuracy: 0.9344 - val_loss: 0.0453 - val_accuracy: 0.9722\n",
      "Epoch 69/150\n",
      "122/122 [==============================] - 0s 142us/step - loss: 0.0619 - accuracy: 0.9344 - val_loss: 0.0452 - val_accuracy: 0.9722\n",
      "Epoch 70/150\n",
      "122/122 [==============================] - 0s 175us/step - loss: 0.0615 - accuracy: 0.9344 - val_loss: 0.0450 - val_accuracy: 0.9722\n",
      "Epoch 71/150\n",
      "122/122 [==============================] - 0s 144us/step - loss: 0.0611 - accuracy: 0.9344 - val_loss: 0.0448 - val_accuracy: 0.9722\n",
      "Epoch 72/150\n",
      "122/122 [==============================] - 0s 162us/step - loss: 0.0610 - accuracy: 0.9344 - val_loss: 0.0444 - val_accuracy: 0.9722\n",
      "Epoch 73/150\n",
      "122/122 [==============================] - 0s 189us/step - loss: 0.0609 - accuracy: 0.9344 - val_loss: 0.0441 - val_accuracy: 0.9722\n",
      "Epoch 74/150\n",
      "122/122 [==============================] - 0s 143us/step - loss: 0.0603 - accuracy: 0.9344 - val_loss: 0.0439 - val_accuracy: 0.9722\n",
      "Epoch 75/150\n",
      "122/122 [==============================] - 0s 226us/step - loss: 0.0602 - accuracy: 0.9344 - val_loss: 0.0436 - val_accuracy: 0.9722\n",
      "Epoch 76/150\n",
      "122/122 [==============================] - 0s 147us/step - loss: 0.0600 - accuracy: 0.9344 - val_loss: 0.0436 - val_accuracy: 0.9722\n",
      "Epoch 77/150\n",
      "122/122 [==============================] - 0s 153us/step - loss: 0.0598 - accuracy: 0.9344 - val_loss: 0.0433 - val_accuracy: 0.9722\n",
      "Epoch 78/150\n",
      "122/122 [==============================] - 0s 172us/step - loss: 0.0599 - accuracy: 0.9344 - val_loss: 0.0432 - val_accuracy: 0.9722\n",
      "Epoch 79/150\n",
      "122/122 [==============================] - 0s 193us/step - loss: 0.0591 - accuracy: 0.9344 - val_loss: 0.0430 - val_accuracy: 0.9722\n",
      "Epoch 80/150\n",
      "122/122 [==============================] - 0s 143us/step - loss: 0.0589 - accuracy: 0.9344 - val_loss: 0.0428 - val_accuracy: 0.9722\n",
      "Epoch 81/150\n",
      "122/122 [==============================] - 0s 173us/step - loss: 0.0589 - accuracy: 0.9344 - val_loss: 0.0425 - val_accuracy: 0.9722\n",
      "Epoch 82/150\n",
      "122/122 [==============================] - 0s 171us/step - loss: 0.0587 - accuracy: 0.9344 - val_loss: 0.0422 - val_accuracy: 0.9722\n",
      "Epoch 83/150\n",
      "122/122 [==============================] - 0s 153us/step - loss: 0.0582 - accuracy: 0.9344 - val_loss: 0.0423 - val_accuracy: 0.9722\n",
      "Epoch 84/150\n",
      "122/122 [==============================] - 0s 199us/step - loss: 0.0582 - accuracy: 0.9344 - val_loss: 0.0425 - val_accuracy: 0.9722\n",
      "Epoch 85/150\n",
      "122/122 [==============================] - 0s 152us/step - loss: 0.0580 - accuracy: 0.9344 - val_loss: 0.0425 - val_accuracy: 0.9722\n",
      "Epoch 86/150\n",
      "122/122 [==============================] - 0s 229us/step - loss: 0.0577 - accuracy: 0.9344 - val_loss: 0.0423 - val_accuracy: 0.9722\n",
      "Epoch 87/150\n",
      "122/122 [==============================] - 0s 149us/step - loss: 0.0578 - accuracy: 0.9344 - val_loss: 0.0422 - val_accuracy: 0.9722\n",
      "Epoch 88/150\n",
      "122/122 [==============================] - 0s 193us/step - loss: 0.0574 - accuracy: 0.9344 - val_loss: 0.0420 - val_accuracy: 0.9722\n",
      "Epoch 89/150\n",
      "122/122 [==============================] - 0s 143us/step - loss: 0.0573 - accuracy: 0.9344 - val_loss: 0.0421 - val_accuracy: 0.9722\n",
      "Epoch 90/150\n",
      "122/122 [==============================] - 0s 187us/step - loss: 0.0570 - accuracy: 0.9344 - val_loss: 0.0418 - val_accuracy: 0.9722\n",
      "Epoch 91/150\n",
      "122/122 [==============================] - 0s 151us/step - loss: 0.0568 - accuracy: 0.9344 - val_loss: 0.0420 - val_accuracy: 0.9722\n",
      "Epoch 92/150\n",
      "122/122 [==============================] - 0s 188us/step - loss: 0.0571 - accuracy: 0.9344 - val_loss: 0.0421 - val_accuracy: 0.9722\n",
      "Epoch 93/150\n",
      "122/122 [==============================] - 0s 148us/step - loss: 0.0566 - accuracy: 0.9344 - val_loss: 0.0420 - val_accuracy: 0.9722\n",
      "Epoch 94/150\n",
      "122/122 [==============================] - 0s 163us/step - loss: 0.0562 - accuracy: 0.9344 - val_loss: 0.0421 - val_accuracy: 0.9722\n",
      "Epoch 95/150\n",
      "122/122 [==============================] - 0s 186us/step - loss: 0.0563 - accuracy: 0.9344 - val_loss: 0.0421 - val_accuracy: 0.9722\n",
      "Epoch 96/150\n",
      "122/122 [==============================] - 0s 150us/step - loss: 0.0561 - accuracy: 0.9344 - val_loss: 0.0423 - val_accuracy: 0.9722\n",
      "Epoch 97/150\n",
      "122/122 [==============================] - 0s 205us/step - loss: 0.0560 - accuracy: 0.9344 - val_loss: 0.0421 - val_accuracy: 0.9722\n",
      "Epoch 98/150\n",
      "122/122 [==============================] - 0s 144us/step - loss: 0.0560 - accuracy: 0.9344 - val_loss: 0.0417 - val_accuracy: 0.9722\n",
      "Epoch 99/150\n",
      "122/122 [==============================] - 0s 194us/step - loss: 0.0558 - accuracy: 0.9344 - val_loss: 0.0420 - val_accuracy: 0.9722\n",
      "Epoch 100/150\n",
      "122/122 [==============================] - 0s 147us/step - loss: 0.0554 - accuracy: 0.9344 - val_loss: 0.0419 - val_accuracy: 0.9722\n",
      "Epoch 101/150\n",
      "122/122 [==============================] - 0s 185us/step - loss: 0.0556 - accuracy: 0.9344 - val_loss: 0.0417 - val_accuracy: 0.9722\n",
      "Epoch 102/150\n",
      "122/122 [==============================] - 0s 155us/step - loss: 0.0552 - accuracy: 0.9344 - val_loss: 0.0417 - val_accuracy: 0.9722\n",
      "Epoch 103/150\n",
      "122/122 [==============================] - 0s 174us/step - loss: 0.0557 - accuracy: 0.9344 - val_loss: 0.0417 - val_accuracy: 0.9722\n",
      "Epoch 104/150\n",
      "122/122 [==============================] - 0s 183us/step - loss: 0.0549 - accuracy: 0.9344 - val_loss: 0.0418 - val_accuracy: 0.9722\n",
      "Epoch 105/150\n",
      "122/122 [==============================] - 0s 154us/step - loss: 0.0548 - accuracy: 0.9344 - val_loss: 0.0415 - val_accuracy: 0.9722\n",
      "Epoch 106/150\n",
      "122/122 [==============================] - 0s 171us/step - loss: 0.0546 - accuracy: 0.9344 - val_loss: 0.0413 - val_accuracy: 0.9722\n",
      "Epoch 107/150\n",
      "122/122 [==============================] - 0s 155us/step - loss: 0.0549 - accuracy: 0.9344 - val_loss: 0.0414 - val_accuracy: 0.9722\n",
      "Epoch 108/150\n",
      "122/122 [==============================] - 0s 188us/step - loss: 0.0545 - accuracy: 0.9344 - val_loss: 0.0412 - val_accuracy: 0.9722\n",
      "Epoch 109/150\n",
      "122/122 [==============================] - 0s 142us/step - loss: 0.0546 - accuracy: 0.9344 - val_loss: 0.0411 - val_accuracy: 0.9722\n",
      "Epoch 110/150\n",
      "122/122 [==============================] - 0s 186us/step - loss: 0.0542 - accuracy: 0.9344 - val_loss: 0.0411 - val_accuracy: 0.9722\n",
      "Epoch 111/150\n",
      "122/122 [==============================] - 0s 146us/step - loss: 0.0545 - accuracy: 0.9344 - val_loss: 0.0413 - val_accuracy: 0.9722\n",
      "Epoch 112/150\n",
      "122/122 [==============================] - 0s 171us/step - loss: 0.0539 - accuracy: 0.9344 - val_loss: 0.0413 - val_accuracy: 0.9722\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 146us/step - loss: 0.0540 - accuracy: 0.9344 - val_loss: 0.0412 - val_accuracy: 0.9722\n",
      "Epoch 114/150\n",
      "122/122 [==============================] - 0s 166us/step - loss: 0.0542 - accuracy: 0.9344 - val_loss: 0.0410 - val_accuracy: 0.9722\n",
      "Epoch 115/150\n",
      "122/122 [==============================] - 0s 166us/step - loss: 0.0540 - accuracy: 0.9344 - val_loss: 0.0409 - val_accuracy: 0.9722\n",
      "Epoch 116/150\n",
      "122/122 [==============================] - 0s 157us/step - loss: 0.0535 - accuracy: 0.9344 - val_loss: 0.0410 - val_accuracy: 0.9722\n",
      "Epoch 117/150\n",
      "122/122 [==============================] - 0s 198us/step - loss: 0.0536 - accuracy: 0.9344 - val_loss: 0.0411 - val_accuracy: 0.9722\n",
      "Epoch 118/150\n",
      "122/122 [==============================] - 0s 145us/step - loss: 0.0540 - accuracy: 0.9344 - val_loss: 0.0411 - val_accuracy: 0.9722\n",
      "Epoch 119/150\n",
      "122/122 [==============================] - 0s 209us/step - loss: 0.0533 - accuracy: 0.9344 - val_loss: 0.0410 - val_accuracy: 0.9722\n",
      "Epoch 120/150\n",
      "122/122 [==============================] - 0s 145us/step - loss: 0.0531 - accuracy: 0.9344 - val_loss: 0.0411 - val_accuracy: 0.9699\n",
      "Epoch 121/150\n",
      "122/122 [==============================] - 0s 162us/step - loss: 0.0533 - accuracy: 0.9344 - val_loss: 0.0411 - val_accuracy: 0.9699\n",
      "Epoch 122/150\n",
      "122/122 [==============================] - 0s 152us/step - loss: 0.0532 - accuracy: 0.9344 - val_loss: 0.0410 - val_accuracy: 0.9699\n",
      "Epoch 123/150\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.88 - 0s 176us/step - loss: 0.0529 - accuracy: 0.9344 - val_loss: 0.0410 - val_accuracy: 0.9699\n",
      "Epoch 124/150\n",
      "122/122 [==============================] - 0s 165us/step - loss: 0.0529 - accuracy: 0.9344 - val_loss: 0.0412 - val_accuracy: 0.9699\n",
      "Epoch 125/150\n",
      "122/122 [==============================] - 0s 163us/step - loss: 0.0528 - accuracy: 0.9344 - val_loss: 0.0412 - val_accuracy: 0.9699\n",
      "Epoch 126/150\n",
      "122/122 [==============================] - 0s 186us/step - loss: 0.0527 - accuracy: 0.9344 - val_loss: 0.0413 - val_accuracy: 0.9699\n",
      "Epoch 127/150\n",
      "122/122 [==============================] - 0s 161us/step - loss: 0.0525 - accuracy: 0.9344 - val_loss: 0.0415 - val_accuracy: 0.9699\n",
      "Epoch 128/150\n",
      "122/122 [==============================] - 0s 196us/step - loss: 0.0526 - accuracy: 0.9344 - val_loss: 0.0416 - val_accuracy: 0.9699\n",
      "Epoch 129/150\n",
      "122/122 [==============================] - 0s 140us/step - loss: 0.0525 - accuracy: 0.9426 - val_loss: 0.0412 - val_accuracy: 0.9699\n",
      "Epoch 130/150\n",
      "122/122 [==============================] - 0s 202us/step - loss: 0.0521 - accuracy: 0.9344 - val_loss: 0.0409 - val_accuracy: 0.9699\n",
      "Epoch 131/150\n",
      "122/122 [==============================] - 0s 146us/step - loss: 0.0524 - accuracy: 0.9344 - val_loss: 0.0405 - val_accuracy: 0.9699\n",
      "Epoch 132/150\n",
      "122/122 [==============================] - 0s 181us/step - loss: 0.0521 - accuracy: 0.9344 - val_loss: 0.0403 - val_accuracy: 0.9699\n",
      "Epoch 133/150\n",
      "122/122 [==============================] - 0s 144us/step - loss: 0.0519 - accuracy: 0.9344 - val_loss: 0.0405 - val_accuracy: 0.9699\n",
      "Epoch 134/150\n",
      "122/122 [==============================] - 0s 167us/step - loss: 0.0519 - accuracy: 0.9344 - val_loss: 0.0406 - val_accuracy: 0.9699\n",
      "Epoch 135/150\n",
      "122/122 [==============================] - 0s 179us/step - loss: 0.0519 - accuracy: 0.9344 - val_loss: 0.0407 - val_accuracy: 0.9699\n",
      "Epoch 136/150\n",
      "122/122 [==============================] - 0s 150us/step - loss: 0.0516 - accuracy: 0.9344 - val_loss: 0.0407 - val_accuracy: 0.9676\n",
      "Epoch 137/150\n",
      "122/122 [==============================] - 0s 214us/step - loss: 0.0519 - accuracy: 0.9426 - val_loss: 0.0407 - val_accuracy: 0.9676\n",
      "Epoch 138/150\n",
      "122/122 [==============================] - 0s 149us/step - loss: 0.0519 - accuracy: 0.9426 - val_loss: 0.0408 - val_accuracy: 0.9676\n",
      "Epoch 139/150\n",
      "122/122 [==============================] - 0s 148us/step - loss: 0.0520 - accuracy: 0.9426 - val_loss: 0.0407 - val_accuracy: 0.9676\n",
      "Epoch 140/150\n",
      "122/122 [==============================] - 0s 174us/step - loss: 0.0515 - accuracy: 0.9426 - val_loss: 0.0405 - val_accuracy: 0.9676\n",
      "Epoch 141/150\n",
      "122/122 [==============================] - 0s 197us/step - loss: 0.0514 - accuracy: 0.9344 - val_loss: 0.0407 - val_accuracy: 0.9676\n",
      "Epoch 142/150\n",
      "122/122 [==============================] - 0s 145us/step - loss: 0.0511 - accuracy: 0.9426 - val_loss: 0.0406 - val_accuracy: 0.9676\n",
      "Epoch 143/150\n",
      "122/122 [==============================] - 0s 166us/step - loss: 0.0512 - accuracy: 0.9426 - val_loss: 0.0403 - val_accuracy: 0.9676\n",
      "Epoch 144/150\n",
      "122/122 [==============================] - 0s 177us/step - loss: 0.0511 - accuracy: 0.9426 - val_loss: 0.0402 - val_accuracy: 0.9676\n",
      "Epoch 145/150\n",
      "122/122 [==============================] - 0s 158us/step - loss: 0.0510 - accuracy: 0.9426 - val_loss: 0.0404 - val_accuracy: 0.9676\n",
      "Epoch 146/150\n",
      "122/122 [==============================] - 0s 179us/step - loss: 0.0512 - accuracy: 0.9426 - val_loss: 0.0405 - val_accuracy: 0.9676\n",
      "Epoch 147/150\n",
      "122/122 [==============================] - 0s 148us/step - loss: 0.0511 - accuracy: 0.9344 - val_loss: 0.0404 - val_accuracy: 0.9676\n",
      "Epoch 148/150\n",
      "122/122 [==============================] - 0s 217us/step - loss: 0.0508 - accuracy: 0.9426 - val_loss: 0.0402 - val_accuracy: 0.9676\n",
      "Epoch 149/150\n",
      "122/122 [==============================] - 0s 141us/step - loss: 0.0512 - accuracy: 0.9426 - val_loss: 0.0402 - val_accuracy: 0.9676\n",
      "Epoch 150/150\n",
      "122/122 [==============================] - 0s 206us/step - loss: 0.0506 - accuracy: 0.9426 - val_loss: 0.0405 - val_accuracy: 0.9676\n"
     ]
    }
   ],
   "source": [
    "#instantiate the model and run it\n",
    "#es = EarlyStopping(monitor='val_loss', patience=30)\n",
    "#mc = ModelCheckpoint('best_model_NOREG.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model1 = create_modelOP()\n",
    "\n",
    "history1 = model1.fit(X_train3, y_train3, \n",
    "                      validation_data=(X_test3, y_test3), \n",
    "                      epochs=150, \n",
    "                      batch_size=25, \n",
    "                      #callbacks=[es,mc]\n",
    "                     ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See if we have overfitting\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(history1['loss'], label='MSE')\n",
    "plt.plot(history1['accuracy'], label='Accuracy', linestyle='dashed')\n",
    "#plt.plot(history1['val_loss'], label='Test')\n",
    "#plt.title('Learning curves for training', fontsize = 18)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See if we have overfitting\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(history1['val_loss'], label='MSE')\n",
    "plt.plot(history1['val_accuracy'], label='Accuracy', linestyle='dashed')\n",
    "#plt.plot(history1['val_loss'], label='Test')\n",
    "#plt.title('Learning curves for test', fontsize = 18)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 0s 19us/step\n"
     ]
    }
   ],
   "source": [
    "mse, accuracy = model1.evaluate(X_test3, y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test 0.9675925970077515\n",
      "MSE on Test 0.040549751888546676\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on Test\", accuracy)\n",
    "print(\"MSE on Test\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 86us/step\n"
     ]
    }
   ],
   "source": [
    "mse_tr, accuracy_tr = model1.evaluate(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training 0.9426229596138\n",
      "MSE on Training 0.0503210794241702\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on Training\", accuracy_tr)\n",
    "print(\"MSE on Training\", mse_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
